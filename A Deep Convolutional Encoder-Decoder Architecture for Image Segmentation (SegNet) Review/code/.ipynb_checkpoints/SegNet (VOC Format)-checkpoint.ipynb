{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:28:36.660329Z",
     "start_time": "2021-01-13T07:28:36.657811Z"
    }
   },
   "source": [
    "## Package load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T18:25:24.171368Z",
     "start_time": "2021-02-22T18:25:24.165867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.4.0\n",
      "GPU 사용 가능 여부: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T12:16:32.884812Z",
     "start_time": "2021-02-22T12:16:32.882310Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16                                      # Mini-batch size    \n",
    "num_epochs = 50\n",
    "learning_rate = 0.0003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (VOC2007 Dataset)\n",
    "\n",
    "- Download VOC2007 dataset from link in references. File should have name VOCtrainval_06-Nov-2007.tar and weight approx 460MB. Extract VOC2007 folder and modify path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:13.994082Z",
     "start_time": "2021-01-14T19:33:13.991082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset v3\n",
    "\n",
    "num_classes = 21                                        # background, airplane, ..., border\n",
    "data_root = \"../data/VOC2007\"                           # Dataset location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:14.318081Z",
     "start_time": "2021-01-14T19:33:14.314582Z"
    }
   },
   "outputs": [],
   "source": [
    "# for reference, not used in this notebook\n",
    "voc_classes = ('background',  # always index 0\n",
    "               'aeroplane', 'bicycle', 'bird', 'boat',  # indices 1, 2, 3, 4\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',  #         5, ...\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor',   #         ..., 21\n",
    "               'border')                                # but border has index 255 (!) / (불필요시 수정 필요)\n",
    "\n",
    "assert num_classes == len(voc_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:14.744255Z",
     "start_time": "2021-01-14T19:33:14.735720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class below reads segmentation dataset in VOC2007 compatible format.\n",
    "\n",
    "class PascalVOCDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Pascal VOC2007 or compatible dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, list_file, img_dir, mask_dir, transform=None):\n",
    "        self.num_classes = num_classes\n",
    "        self.images = open(list_file, \"rt\").read().split(\"\\n\")[:-1]\n",
    "        self.transform = transform\n",
    "        self.img_extension = \".jpg\"\n",
    "        self.mask_extension = \".png\"\n",
    "        self.image_root_dir = img_dir\n",
    "        self.mask_root_dir = mask_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        name = self.images[index]\n",
    "        image_path = os.path.join(self.image_root_dir, name + self.img_extension)\n",
    "        mask_path = os.path.join(self.mask_root_dir, name + self.mask_extension)\n",
    "\n",
    "        image = self.load_image(path=image_path)\n",
    "        gt_mask = self.load_mask(path=mask_path)\n",
    "\n",
    "        return torch.FloatTensor(image), torch.LongTensor(gt_mask)\n",
    "\n",
    "    \n",
    "    def load_image(self, path=None):\n",
    "        raw_image = PIL.Image.open(path)\n",
    "        raw_image = np.transpose(raw_image.resize((224, 224)), (2,1,0))\n",
    "        imx_t = np.array(raw_image, dtype=np.float32)/255.0\n",
    "        return imx_t\n",
    "\n",
    "    \n",
    "    def load_mask(self, path=None):\n",
    "        raw_image = PIL.Image.open(path)\n",
    "        raw_image = raw_image.resize((224, 224))\n",
    "        imx_t = np.array(raw_image)\n",
    "        imx_t[imx_t==255] = self.num_classes-1        # convert VOC border into last class\n",
    "        return imx_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:15.465220Z",
     "start_time": "2021-01-14T19:33:15.462719Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_root, 'ImageSets/Segmentation/train.txt')\n",
    "val_path = os.path.join(data_root, 'ImageSets/Segmentation/val.txt')\n",
    "\n",
    "img_dir = os.path.join(data_root, \"JPEGImages\")\n",
    "mask_dir = os.path.join(data_root, \"SegmentationClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Create train and validation datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:15.951607Z",
     "start_time": "2021-01-14T19:33:15.948107Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = PascalVOCDataset(num_classes = num_classes, \n",
    "                                 list_file = train_path,\n",
    "                                 img_dir = img_dir, \n",
    "                                 mask_dir=mask_dir)\n",
    "\n",
    "val_dataset = PascalVOCDataset(num_classes = num_classes, \n",
    "                               list_file=val_path,\n",
    "                               img_dir=img_dir, \n",
    "                               mask_dir=mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:16.243021Z",
     "start_time": "2021-01-14T19:33:16.239524Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:16.503022Z",
     "start_time": "2021-01-14T19:33:16.495023Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train Dataset:')\n",
    "print('  length:', len(train_dataset))\n",
    "print(\"------------------------\")\n",
    "print('Validation Dataset:')\n",
    "print('  length:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 샘플 시각화 (Show example image and mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:17.360578Z",
     "start_time": "2021-01-14T19:33:17.150080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image, mask = train_dataset[10]\n",
    "image.transpose_(0, 2)\n",
    "\n",
    "print('image shape:', list(image.shape))\n",
    "print('mask shape: ', list(mask.shape))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8,4))\n",
    "ax1.imshow(image)\n",
    "ax2.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:17.530997Z",
     "start_time": "2021-01-14T19:33:17.523498Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "mask array에 들어있는 unique value 로 각각 의미하는 label은 아래와 같음\n",
    "0 : background\n",
    "5 : bottle\n",
    "20 : tvmonitor\n",
    "21 : border\n",
    "'''\n",
    "\n",
    "set(mask.numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 설계 (Pretrained 되지 않은 모델 사용) \n",
    "- SegNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drive.google.com/uc?export=view&id=1yzT-L_cXlbgJLnruD4IA1K2riHZE54ZA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:06:14.378005Z",
     "start_time": "2021-02-22T17:06:14.359505Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(SegNet, self).__init__()\n",
    "        def CBR(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)\n",
    "            return cbr\n",
    "        \n",
    "        # conv1 \n",
    "        self.cbr1_1 = CBR(3, 64, 3, 1, 1)\n",
    "        self.cbr1_2 = CBR(64, 64, 3, 1, 1)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv2 \n",
    "        self.cbr2_1 = CBR(64, 128, 3, 1, 1)\n",
    "        self.cbr2_2 = CBR(128, 128, 3, 1, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv3\n",
    "        self.cbr3_1 = CBR(128, 256, 3, 1, 1)\n",
    "        self.cbr3_2 = CBR(256, 256, 3, 1, 1)\n",
    "        self.cbr3_3 = CBR(256, 256, 3, 1, 1)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv4\n",
    "        self.cbr4_1 = CBR(256, 512, 3, 1, 1)\n",
    "        self.cbr4_2 = CBR(512, 512, 3, 1, 1)\n",
    "        self.cbr4_3 = CBR(512, 512, 3, 1, 1)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv5\n",
    "        self.cbr5_1 = CBR(512, 512, 3, 1, 1)\n",
    "        self.cbr5_2 = CBR(512, 512, 3, 1, 1)\n",
    "        self.cbr5_3 = CBR(512, 512, 3, 1, 1)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "        \n",
    "        # deconv5\n",
    "        self.unpool5 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcbr5_3 = CBR(512, 512, 3, 1, 1)\n",
    "        self.dcbr5_2 = CBR(512, 512, 3, 1, 1)\n",
    "        self.dcbr5_1 = CBR(512, 512, 3, 1, 1)\n",
    "\n",
    "        # deconv4 \n",
    "        self.unpool4 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcbr4_3 = CBR(512, 512, 3, 1, 1)\n",
    "        self.dcbr4_2 = CBR(512, 512, 3, 1, 1)\n",
    "        self.dcbr4_1 = CBR(512, 256, 3, 1, 1)\n",
    "\n",
    "        # deconv3\n",
    "        self.unpool3 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcbr3_3 = CBR(256, 256, 3, 1, 1)\n",
    "        self.dcbr3_2 = CBR(256, 256, 3, 1, 1)\n",
    "        self.dcbr3_1 = CBR(256, 128, 3, 1, 1)\n",
    "\n",
    "        # deconv2\n",
    "        self.unpool2 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcbr2_2 = CBR(128, 128, 3, 1, 1)\n",
    "        self.dcbr2_1 = CBR(128, 64, 3, 1, 1)\n",
    "\n",
    "        # deconv1\n",
    "        self.unpool1 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcbr1_2 = CBR(64, 64, 3, 1, 1)\n",
    "        self.dcbr1_1 = CBR(64, 64, 3, 1, 1)\n",
    "        self.score_fr = nn.Conv2d(64, num_classes, kernel_size = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.cbr1_1(x)\n",
    "        h = self.cbr1_2(h)\n",
    "        dim1 = h.size()\n",
    "        h, pool1_indices = self.pool1(h)\n",
    "        \n",
    "        h = self.cbr2_1(h)\n",
    "        h = self.cbr2_2(h)\n",
    "        dim2 = h.size()\n",
    "        h, pool2_indices = self.pool2(h)\n",
    "        \n",
    "        h = self.cbr3_1(h)\n",
    "        h = self.cbr3_2(h)\n",
    "        h = self.cbr3_3(h)\n",
    "        dim3 = h.size()\n",
    "        h, pool3_indices = self.pool3(h)\n",
    "        \n",
    "        h = self.cbr4_1(h)\n",
    "        h = self.cbr4_2(h)\n",
    "        h = self.cbr4_3(h)\n",
    "        dim4 = h.size()\n",
    "        h, pool4_indices = self.pool4(h)\n",
    "        \n",
    "        h = self.cbr5_1(h)\n",
    "        h = self.cbr5_2(h)\n",
    "        h = self.cbr5_3(h)\n",
    "        dim5 = h.size()\n",
    "        h, pool5_indices = self.pool5(h)\n",
    "        \n",
    "        h = self.unpool5(h, pool5_indices, output_size = dim5)\n",
    "        h = self.dcbr5_3(h)\n",
    "        h = self.dcbr5_2(h)\n",
    "        h = self.dcbr5_1(h)\n",
    "        \n",
    "        h = self.unpool4(h, pool4_indices, output_size = dim4)\n",
    "        h = self.dcbr4_3(h)\n",
    "        h = self.dcbr4_2(h)\n",
    "        h = self.dcbr4_1(h)\n",
    "        \n",
    "        h = self.unpool3(h, pool3_indices, output_size = dim3)\n",
    "        h = self.dcbr3_3(h)\n",
    "        h = self.dcbr3_2(h)\n",
    "        h = self.dcbr3_1(h)\n",
    "        \n",
    "        h = self.unpool2(h, pool2_indices, output_size = dim2)\n",
    "        h = self.dcbr2_2(h)\n",
    "        h = self.dcbr2_1(h)\n",
    "        \n",
    "        h = self.unpool1(h, pool1_indices, output_size = dim1)\n",
    "        h = self.dcbr1_2(h)\n",
    "        h = self.dcbr1_1(h)\n",
    "        h = self.score_fr(h)       \n",
    "        \n",
    "        return torch.sigmoid(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:06:19.866296Z",
     "start_time": "2021-02-22T17:06:19.861297Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:14:30.359775Z",
     "start_time": "2021-02-22T17:14:30.225772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape :  torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "\n",
    "model = SegNet(num_classes=21)\n",
    "x = torch.randn([1, 3, 224, 224])\n",
    "print(\"input shape : \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:14:32.799742Z",
     "start_time": "2021-02-22T17:14:31.623742Z"
    }
   },
   "outputs": [],
   "source": [
    "out = model(x)\n",
    "#print(\"output shape : \", out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:14:45.910465Z",
     "start_time": "2021-02-22T17:14:34.742965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-Time: 1.1040 s\n",
      "Run-Time: 1.1135 s\n",
      "Run-Time: 1.1235 s\n",
      "Run-Time: 1.1115 s\n",
      "Run-Time: 1.1190 s\n",
      "Run-Time: 1.1045 s\n",
      "Run-Time: 1.1170 s\n",
      "Run-Time: 1.1150 s\n",
      "Run-Time: 1.1040 s\n",
      "Run-Time: 1.1345 s\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "model.eval()\n",
    "for idx in range(10):\n",
    "    input = Variable(torch.rand([3, 224, 224]).unsqueeze(0), requires_grad=False)\n",
    "    start_time = time.time()\n",
    "    out = model(input)\n",
    "    torch.cuda.synchronize()\n",
    "    time_taken = time.time() - start_time\n",
    "    print(\"Run-Time: %.4f s\" % time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T17:37:13.781560Z",
     "start_time": "2021-02-22T17:37:13.686559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-7  [[-1, 64, 112, 112], [-1, 64, 112, 112]]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
      "             ReLU-10        [-1, 128, 112, 112]               0\n",
      "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
      "             ReLU-13        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-14  [[-1, 128, 56, 56], [-1, 128, 56, 56]]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
      "             ReLU-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
      "             ReLU-20          [-1, 256, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
      "             ReLU-23          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-24  [[-1, 256, 28, 28], [-1, 256, 28, 28]]               0\n",
      "           Conv2d-25          [-1, 512, 28, 28]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-27          [-1, 512, 28, 28]               0\n",
      "           Conv2d-28          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-30          [-1, 512, 28, 28]               0\n",
      "           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-33          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-34  [[-1, 512, 14, 14], [-1, 512, 14, 14]]               0\n",
      "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-36          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-37          [-1, 512, 14, 14]               0\n",
      "           Conv2d-38          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-39          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-40          [-1, 512, 14, 14]               0\n",
      "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-43          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-44  [[-1, 512, 7, 7], [-1, 512, 7, 7]]               0\n",
      "      MaxUnpool2d-45          [-1, 512, 14, 14]               0\n",
      "           Conv2d-46          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-47          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-48          [-1, 512, 14, 14]               0\n",
      "           Conv2d-49          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-50          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-51          [-1, 512, 14, 14]               0\n",
      "           Conv2d-52          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-53          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-54          [-1, 512, 14, 14]               0\n",
      "      MaxUnpool2d-55          [-1, 512, 28, 28]               0\n",
      "           Conv2d-56          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-57          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "           Conv2d-62          [-1, 256, 28, 28]       1,179,904\n",
      "      BatchNorm2d-63          [-1, 256, 28, 28]             512\n",
      "             ReLU-64          [-1, 256, 28, 28]               0\n",
      "      MaxUnpool2d-65          [-1, 256, 56, 56]               0\n",
      "           Conv2d-66          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-67          [-1, 256, 56, 56]             512\n",
      "             ReLU-68          [-1, 256, 56, 56]               0\n",
      "           Conv2d-69          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-70          [-1, 256, 56, 56]             512\n",
      "             ReLU-71          [-1, 256, 56, 56]               0\n",
      "           Conv2d-72          [-1, 128, 56, 56]         295,040\n",
      "      BatchNorm2d-73          [-1, 128, 56, 56]             256\n",
      "             ReLU-74          [-1, 128, 56, 56]               0\n",
      "      MaxUnpool2d-75        [-1, 128, 112, 112]               0\n",
      "           Conv2d-76        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-77        [-1, 128, 112, 112]             256\n",
      "             ReLU-78        [-1, 128, 112, 112]               0\n",
      "           Conv2d-79         [-1, 64, 112, 112]          73,792\n",
      "      BatchNorm2d-80         [-1, 64, 112, 112]             128\n",
      "             ReLU-81         [-1, 64, 112, 112]               0\n",
      "      MaxUnpool2d-82         [-1, 64, 224, 224]               0\n",
      "           Conv2d-83         [-1, 64, 224, 224]          36,928\n",
      "      BatchNorm2d-84         [-1, 64, 224, 224]             128\n",
      "             ReLU-85         [-1, 64, 224, 224]               0\n",
      "           Conv2d-86         [-1, 64, 224, 224]          36,928\n",
      "      BatchNorm2d-87         [-1, 64, 224, 224]             128\n",
      "             ReLU-88         [-1, 64, 224, 224]               0\n",
      "           Conv2d-89         [-1, 21, 224, 224]           1,365\n",
      "================================================================\n",
      "Total params: 29,481,429\n",
      "Trainable params: 29,481,429\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 14047.26\n",
      "Params size (MB): 112.46\n",
      "Estimated Total Size (MB): 14160.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model.to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가독성 있는 코드로 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T18:25:38.249454Z",
     "start_time": "2021-02-22T18:25:38.227453Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class DeconvNet(nn.Module):\n",
    "    def __init__(self, num_classes=21):\n",
    "        super(DeconvNet, self).__init__()\n",
    "        def CBR(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "            layers = []\n",
    "            layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            layers += [nn.ReLU()]\n",
    "\n",
    "            cbr = nn.Sequential(*layers)\n",
    "            return cbr\n",
    "        \n",
    "        def DCB(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "            layers = []\n",
    "            layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding)]\n",
    "            layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
    "            cbr = nn.Sequential(*layers)\n",
    "            return cbr\n",
    "        \n",
    "        # conv1 \n",
    "        self.cbr1_1 = CBR(3, 64, 3, 1, 1)\n",
    "        self.cbr1_2 = CBR(64, 64, 3, 1, 1)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv2 \n",
    "        self.cbr2_1 = CBR(64, 128, 3, 1, 1)\n",
    "        self.cbr2_2 = CBR(128, 128, 3, 1, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv3\n",
    "        self.cbr3_1 = CBR(128, 256, 3, 1, 1)\n",
    "        self.cbr3_2 = CBR(256, 256, 3, 1, 1)\n",
    "        self.cbr3_3 = CBR(256, 256, 3, 1, 1)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv4\n",
    "        self.cbr4_1 = CBR(256, 512, 3, 1, 1)\n",
    "        self.cbr4_2 = CBR(512, 512, 3, 1, 1)\n",
    "        self.cbr4_3 = CBR(512, 512, 3, 1, 1)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "\n",
    "        # conv5\n",
    "        self.cbr5_1 = CBR(512, 512, 3, 1, 1)\n",
    "        self.cbr5_2 = CBR(512, 512, 3, 1, 1)\n",
    "        self.cbr5_3 = CBR(512, 512, 3, 1, 1)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True, return_indices=True) \n",
    "        \n",
    "        # fc1\n",
    "        self.fc6 = CBR(512, 4096, 1, 1, 0)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc2\n",
    "        self.fc7 = CBR(4096, 4096, 1, 1, 0)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        # Deconv\n",
    "        self.dcb6 = DCB(4096, 512, 7, 1, 3)    \n",
    "        \n",
    "        # Deconv5\n",
    "        self.unpool5 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcb5_3 = DCB(512, 512, 3, 1, 1)\n",
    "        self.dcb5_2 = DCB(512, 512, 3, 1, 1)\n",
    "        self.dcb5_1 = DCB(512, 512, 3, 1, 1)\n",
    "\n",
    "        # Deconv4\n",
    "        self.unpool4 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcb4_3 = DCB(512, 512, 3, 1, 1)\n",
    "        self.dcb4_2 = DCB(512, 512, 3, 1, 1)\n",
    "        self.dcb4_1 = DCB(512, 256, 3, 1, 1)\n",
    "        \n",
    "        # Deconv3\n",
    "        self.unpool3 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcb3_3 = DCB(256, 256, 3, 1, 1)\n",
    "        self.dcb3_2 = DCB(256, 256, 3, 1, 1)\n",
    "        self.dcb3_1 = DCB(256, 128, 3, 1, 1)\n",
    "        \n",
    "        # Deconv2\n",
    "        self.unpool2 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcb2_2 = DCB(128, 128, 3, 1, 1)\n",
    "        self.dcb2_1 = DCB(128, 64, 3, 1, 1)\n",
    "        \n",
    "        # Deconv1\n",
    "        self.unpool1 = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.dcb1_2 = DCB(64, 64, 3, 1, 1)\n",
    "        self.dcb1_1 = DCB(64, 64, 3, 1, 1)\n",
    "        self.score_fr = nn.Conv2d(64, num_classes, kernel_size = 1)\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "                # xavier_uniform은 bias에 대해서는 제공하지 않음 \n",
    "                # ValueError: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.cbr1_1(x)\n",
    "        h = self.cbr1_2(h)\n",
    "        h, pool1_indices = self.pool1(h)\n",
    "        \n",
    "        h = self.cbr2_1(h)\n",
    "        h = self.cbr2_2(h)\n",
    "        h, pool2_indices = self.pool2(h)\n",
    "        \n",
    "        h = self.cbr3_1(h)\n",
    "        h = self.cbr3_2(h)\n",
    "        h = self.cbr3_3(h)\n",
    "        h, pool3_indices = self.pool3(h)\n",
    "        \n",
    "        h = self.cbr4_1(h)\n",
    "        h = self.cbr4_2(h)\n",
    "        h = self.cbr4_3(h)\n",
    "        h, pool4_indices = self.pool4(h)\n",
    "        \n",
    "        h = self.cbr5_1(h)\n",
    "        h = self.cbr5_2(h)\n",
    "        h = self.cbr5_3(h)\n",
    "        h, pool5_indices = self.pool5(h)\n",
    "        \n",
    "        h = self.fc6(h)\n",
    "        h = self.drop6(h)\n",
    "\n",
    "        h = self.fc7(h)\n",
    "        h = self.drop7(h)\n",
    "        \n",
    "        h = self.dcb6(h)\n",
    "        \n",
    "        h = self.unpool5(h, pool5_indices)\n",
    "        h = self.dcb5_3(h)\n",
    "        h = self.dcb5_2(h)\n",
    "        h = self.dcb5_1(h)\n",
    "        \n",
    "        h = self.unpool4(h, pool4_indices)\n",
    "        h = self.dcb4_3(h)\n",
    "        h = self.dcb4_2(h)\n",
    "        h = self.dcb4_1(h)\n",
    "        \n",
    "        h = self.unpool3(h, pool3_indices)\n",
    "        h = self.dcb3_3(h)\n",
    "        h = self.dcb3_2(h)\n",
    "        h = self.dcb3_1(h)\n",
    "        \n",
    "        h = self.unpool2(h, pool2_indices)\n",
    "        h = self.dcb2_2(h)\n",
    "        h = self.dcb2_1(h)\n",
    "        \n",
    "        h = self.unpool1(h, pool1_indices)\n",
    "        h = self.dcb1_2(h)\n",
    "        h = self.dcb1_1(h)\n",
    "        h = self.score_fr(h)        \n",
    "        return torch.sigmoid(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T18:28:54.387331Z",
     "start_time": "2021-02-22T18:28:53.246358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape :  torch.Size([1, 3, 224, 224])\n",
      "output shape :  torch.Size([1, 21, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 구현된 model에 임의의 input을 넣어 output이 잘 나오는지 test\n",
    "\n",
    "SegNet_model = SegNet(num_classes=21)\n",
    "x = torch.randn([1, 3, 224, 224])\n",
    "print(\"input shape : \", x.shape)\n",
    "out = model(x)\n",
    "print(\"output shape : \", out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-22T18:29:00.636Z"
    }
   },
   "outputs": [],
   "source": [
    "out = SegNet_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T18:27:59.022162Z",
     "start_time": "2021-02-22T18:27:48.515163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run-Time: 1.0615 s\n",
      "Run-Time: 1.0275 s\n",
      "Run-Time: 1.0445 s\n",
      "Run-Time: 1.0265 s\n",
      "Run-Time: 1.0275 s\n",
      "Run-Time: 1.0770 s\n",
      "Run-Time: 1.0475 s\n",
      "Run-Time: 1.0585 s\n",
      "Run-Time: 1.0695 s\n",
      "Run-Time: 1.0485 s\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "model.eval()\n",
    "for idx in range(10):\n",
    "    input = Variable(torch.rand([3, 224, 224]).unsqueeze(0), requires_grad=False)\n",
    "    start_time = time.time()\n",
    "    out = SegNet_model(input)\n",
    "    torch.cuda.synchronize()\n",
    "    time_taken = time.time() - start_time\n",
    "    print(\"Run-Time: %.4f s\" % time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:20.858721Z",
     "start_time": "2021-01-14T19:33:20.852721Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    best_loss = 9999999\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (image, mask) in enumerate(data_loader):\n",
    "            image = image.type(torch.float32)\n",
    "            mask = mask.type(torch.long)\n",
    "            print(image[0].shape)\n",
    "            print('------------')\n",
    "            print(mask[0].shape)     \n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "            \n",
    "            outputs = model(image) \n",
    "            print('------------')\n",
    "            print(outputs[0].shape)\n",
    "            loss = criterion(outputs, mask)\n",
    "            \n",
    "            optimizer.zero_grad()          \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n",
    "                \n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, cross_entropy2d, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:21.406317Z",
     "start_time": "2021-01-14T19:33:21.401289Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        for step, (image, mask) in enumerate(data_loader):\n",
    "            image = image.type(torch.float32)\n",
    "            mask = mask.type(torch.long)\n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, mask)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "        avrg_loss = total_loss / cnt\n",
    "        print('Validation #{}  Average Loss: {:.4f}'.format(epoch, avrg_loss))\n",
    "   \n",
    "    model.train()\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:22.441888Z",
     "start_time": "2021-01-14T19:33:22.439387Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, saved_dir, file_name='model.pt'):\n",
    "    check_point = {\n",
    "        'net': model.state_dict()\n",
    "    }\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  모델 생성 및 Loss function, Optimizer 정의\n",
    "\n",
    "- [다중분류를 위한 대표적인 손실함수 : `torch.nn.CrossEntropyLoss`](http://www.gisdeveloper.co.kr/?p=8668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:30:06.778772Z",
     "start_time": "2021-01-14T19:30:06.773273Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross_entropy 동작 원리 : \n",
    "\n",
    "output = torch.Tensor(\n",
    "    [\n",
    "        [0.8982, 0.805, 0.6393, 0.9983, 0.5731, 0.0469, 0.556, 0.1476, 0.8404, 0.5544],\n",
    "        [0.9457, 0.0195, 0.9846, 0.3231, 0.1605, 0.3143, 0.9508, 0.2762, 0.7276, 0.4332]\n",
    "    ]\n",
    ")\n",
    "target = torch.LongTensor([1.4, 5.3])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output, target)\n",
    "\n",
    "print(loss) # tensor(2.3519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:25.479776Z",
     "start_time": "2021-01-14T19:33:25.475777Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def criterion(input, target, weight=None, size_average=True):\n",
    "    '''\n",
    "    cross_entropy2d\n",
    "    '''\n",
    "    n, c, h, w = input.size()\n",
    "    nt, ht, wt = target.size()\n",
    "\n",
    "    # Handle inconsistent size between input and target\n",
    "    if h != ht and w != wt:  # upsample labels\n",
    "        input = F.interpolate(input, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "    input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
    "    target = torch.LongTensor(target.view(-1))  # target의 type을 lnt로 명시적으로 변환\n",
    "    \n",
    "#     print('input : {}'.format(input.shape))\n",
    "#     print('target : {}'.format(target.shape))\n",
    "#     print('first target index : {}'.format(target[0]))\n",
    "\n",
    "    loss = F.cross_entropy(\n",
    "        input, target, weight=weight, size_average=size_average, ignore_index=250\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:29.965238Z",
     "start_time": "2021-01-14T19:33:26.691740Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross_entropy2d() test\n",
    "model = fcn32(num_classes=22)\n",
    "input = np.transpose(image, [2, 1, 0]).reshape([1, 3, 224, 224])\n",
    "out = model(input)\n",
    "criterion(out,  mask.reshape([1,224,224]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T19:33:34.430271Z",
     "start_time": "2021-01-14T19:33:31.691273Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(7777) \n",
    "\n",
    "model = fcn32(num_classes=22)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)   \n",
    "\n",
    "val_every = 1\n",
    "saved_dir = './saved/FCN32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-14T19:33:35.605Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:51:27.414006Z",
     "start_time": "2021-01-13T07:51:27.411008Z"
    }
   },
   "source": [
    "## Reference\n",
    "- [dataloader using VOC2007 Dataset](https://marcinbogdanski.github.io/ai-sketchpad/PyTorchNN/1630_PT_SegNet_VOC2007.html)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.097px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
