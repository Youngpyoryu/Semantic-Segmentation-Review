<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>(SegNet) A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</title><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none 0s ease 0s; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
mark .md-meta { color: rgb(0, 0, 0); opacity: 0.3 !important; }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-require-zoom-fix foreignobject { font-size: var(--mermaid-font-zoom); }


:root {
  --mermaid-theme: night;
  --node-fill: #BDD5EA;
}

[lang='mermaid'] .label {
  color: #333;
}

/* CSS Document */

/** code highlight */

.cm-s-inner .cm-variable,
.cm-s-inner .cm-operator,
.cm-s-inner .cm-property {
    color: #b8bfc6;
}

.cm-s-inner .cm-keyword {
    color: #C88FD0;
}

.cm-s-inner .cm-tag {
    color: #7DF46A;
}

.cm-s-inner .cm-attribute {
    color: #7575E4;
}

.CodeMirror div.CodeMirror-cursor {
    border-left: 1px solid #b8bfc6;
    z-index: 3;
}

.cm-s-inner .cm-string {
    color: #D26B6B;
}

.cm-s-inner .cm-comment,
.cm-s-inner.cm-comment {
    color: #DA924A;
}

.cm-s-inner .cm-header,
.cm-s-inner .cm-def,
.cm-s-inner.cm-header,
.cm-s-inner.cm-def {
    color: #8d8df0;
}

.cm-s-inner .cm-quote,
.cm-s-inner.cm-quote {
    color: #57ac57;
}

.cm-s-inner .cm-hr {
    color: #d8d5d5;
}

.cm-s-inner .cm-link {
    color: #d3d3ef;
}

.cm-s-inner .cm-negative {
    color: #d95050;
}

.cm-s-inner .cm-positive {
    color: #50e650;
}

.cm-s-inner .cm-string-2 {
    color: #f50;
}

.cm-s-inner .cm-meta,
.cm-s-inner .cm-qualifier {
    color: #b7b3b3;
}

.cm-s-inner .cm-builtin {
    color: #f3b3f8;
}

.cm-s-inner .cm-bracket {
    color: #997;
}

.cm-s-inner .cm-atom,
.cm-s-inner.cm-atom {
    color: #84B6CB;
}

.cm-s-inner .cm-number {
    color: #64AB8F;
}

.cm-s-inner .cm-variable {
    color: #b8bfc6;
}

.cm-s-inner .cm-variable-2 {
    color: #9FBAD5;
}

.cm-s-inner .cm-variable-3 {
    color: #1cc685;
}

.CodeMirror-selectedtext,
.CodeMirror-selected {
    background: #4a89dc;
    color: #fff !important;
    text-shadow: none;
}

.CodeMirror-gutters {
    border-right: none;
}

/* CSS Document */

/** markdown source **/
.cm-s-typora-default .cm-header, 
.cm-s-typora-default .cm-property
{
    color: #cebcca;
}

.CodeMirror.cm-s-typora-default div.CodeMirror-cursor{
    border-left: 3px solid #b8bfc6;
}

.cm-s-typora-default .cm-comment {
    color: #9FB1FF;
}

.cm-s-typora-default .cm-string {
    color: #A7A7D9
}

.cm-s-typora-default .cm-atom, .cm-s-typora-default .cm-number {
    color: #848695;
    font-style: italic;
}

.cm-s-typora-default .cm-link {
    color: #95B94B;
}

.cm-s-typora-default .CodeMirror-activeline-background {
    background: rgba(51, 51, 51, 0.72);
}

.cm-s-typora-default .cm-comment, .cm-s-typora-default .cm-code {
	color: #8aa1e1;
}@import "";
@import "";
@import "";

:root {
    --bg-color:  #363B40;
    --side-bar-bg-color: #2E3033;
    --text-color: #b8bfc6;

    --select-text-bg-color:#4a89dc;

    --item-hover-bg-color: #0a0d16;
    --control-text-color: #b7b7b7;
    --control-text-hover-color: #eee;
    --window-border: 1px solid #555;

    --active-file-bg-color: rgb(34, 34, 34);
    --active-file-border-color: #8d8df0;

    --primary-color: #a3d5fe;

    --active-file-text-color: white;
    --item-hover-bg-color: #70717d;
    --item-hover-text-color: white;
    --primary-color: #6dc1e7;

    --rawblock-edit-panel-bd: #333;

    --search-select-bg-color: #428bca;
}

html {
    font-size: 16px;
}

html,
body {
    -webkit-text-size-adjust: 100%;
    -ms-text-size-adjust: 100%;
    background: #363B40;
    background: var(--bg-color);
    fill: currentColor;
    line-height: 1.625rem;
}

#write {
    max-width: 914px;
}


@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1024px;
	}
}

@media only screen and (min-width: 1800px) {
	#write {
		max-width: 1200px;
	}
}

html,
body,
button,
input,
select,
textarea,
div.code-tooltip-content {
    color: #b8bfc6;
    border-color: transparent;
}

div.code-tooltip,
.md-hover-tip .md-arrow:after {
    background: #333;
}

.popover.bottom > .arrow:after {
    border-bottom-color: #333;
}

html,
body,
button,
input,
select,
textarea {
    font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}

hr {
    height: 2px;
    border: 0;
    margin: 24px 0 !important;
}

h1,
h2,
h3,
h4,
h5,
h6 {
    font-family: "Lucida Grande", "Corbel", sans-serif;
    font-weight: normal;
    clear: both;
    -ms-word-wrap: break-word;
    word-wrap: break-word;
    margin: 0;
    padding: 0;
    color: #DEDEDE
}

h1 {
    font-size: 2.5rem;
    /* 36px */
    line-height: 2.75rem;
    /* 40px */
    margin-bottom: 1.5rem;
    /* 24px */
    letter-spacing: -1.5px;
}

h2 {
    font-size: 1.63rem;
    /* 24px */
    line-height: 1.875rem;
    /* 30px */
    margin-bottom: 1.5rem;
    /* 24px */
    letter-spacing: -1px;
    font-weight: bold;
}

h3 {
    font-size: 1.17rem;
    /* 18px */
    line-height: 1.5rem;
    /* 24px */
    margin-bottom: 1.5rem;
    /* 24px */
    letter-spacing: -1px;
    font-weight: bold;
}

h4 {
    font-size: 1.12rem;
    /* 16px */
    line-height: 1.375rem;
    /* 22px */
    margin-bottom: 1.5rem;
    /* 24px */
    color: white;
}

h5 {
    font-size: 0.97rem;
    /* 16px */
    line-height: 1.25rem;
    /* 22px */
    margin-bottom: 1.5rem;
    /* 24px */
    font-weight: bold;
}

h6 {
    font-size: 0.93rem;
    /* 16px */
    line-height: 1rem;
    /* 16px */
    margin-bottom: 0.75rem;
    color: white;
}

@media (min-width: 980px) {
    h3.md-focus:before,
    h4.md-focus:before,
    h5.md-focus:before,
    h6.md-focus:before {
        color: #ddd;
        border: 1px solid #ddd;
        border-radius: 3px;
        position: absolute;
        left: -1.642857143rem;
        top: .357142857rem;
        float: left;
        font-size: 9px;
        padding-left: 2px;
        padding-right: 2px;
        vertical-align: bottom;
        font-weight: normal;
        line-height: normal;
    }

    h3.md-focus:before {
        content: 'h3';
    }

    h4.md-focus:before {
        content: 'h4';
    }

    h5.md-focus:before {
        content: 'h5';
        top: 0px;
    }

    h6.md-focus:before {
        content: 'h6';
        top: 0px;
    }
}

a {
    text-decoration: none;
    outline: 0;
}

a:hover {
    outline: 0;
}

a:focus {
    outline: thin dotted;
}

sup.md-footnote {
    background-color: #555;
    color: #ddd;
}

p {
    -ms-word-wrap: break-word;
    word-wrap: break-word;
}

p,
ul,
dd,
ol,
hr,
address,
pre,
table,
iframe,
.wp-caption,
.wp-audio-shortcode,
.wp-video-shortcode {
    margin-top: 0;
    margin-bottom: 1.5rem;
    /* 24px */
}

audio:not([controls]) {
    display: none;
}

[hidden] {
    display: none;
}

::-moz-selection {
    background: #4a89dc;
    color: #fff;
    text-shadow: none;
}

*.in-text-selection,
::selection {
    background: #4a89dc;
    color: #fff;
    text-shadow: none;
}

ul,
ol {
    padding: 0 0 0 1.875rem;
    /* 30px */
}

ul {
    list-style: square;
}

ol {
    list-style: decimal;
}

ul ul,
ol ol,
ul ol,
ol ul {
    margin: 0;
}

b,
th,
dt,
strong {
    font-weight: bold;
}

i,
em,
dfn,
cite {
    font-style: italic;
}

blockquote {
    padding-left: 1.875rem;
    margin: 0 0 1.875rem 1.875rem;
    border-left: solid 2px #474d54;
    padding-left: 30px;
    margin-top: 35px;
}

pre,
code,
kbd,
tt,
var {
    font-size: 0.875rem;
    font-family: Monaco, Consolas, "Andale Mono", "DejaVu Sans Mono", monospace;
}

code,
tt,
var {
    background: rgba(0, 0, 0, 0.05);
}

kbd {
    padding: 2px 4px;
    font-size: 90%;
    color: #fff;
    background-color: #333;
    border-radius: 3px;
    box-shadow: inset 0 -1px 0 rgba(0,0,0,.25);
}

pre.md-fences {
    padding: 10px 10px 10px 30px;
    margin-bottom: 20px;
    background: #333;
}

.CodeMirror-gutters {
    background: #333;
    border-right: 1px solid transparent;
}

.enable-diagrams pre.md-fences[lang="sequence"] .code-tooltip,
.enable-diagrams pre.md-fences[lang="flow"] .code-tooltip,
.enable-diagrams pre.md-fences[lang="mermaid"] .code-tooltip {
    bottom: -2.2em;
    right: 4px;
}

code,
kbd,
tt,
var {
    padding: 2px 5px;
}

table {
    max-width: 100%;
    width: 100%;
    border-collapse: collapse;
    border-spacing: 0;
}

th,
td {
    padding: 5px 10px;
    vertical-align: top;
}

a {
    -webkit-transition: all .2s ease-in-out;
    transition: all .2s ease-in-out;
}

hr {
    background: #474d54;
    /* variable */
}

h1 {
    margin-top: 2em;
}

a {
    color: #e0e0e0;
    text-decoration: underline;
}

a:hover {
    color: #fff;
}

.md-inline-math script {
    color: #81b1db;
}

b,
th,
dt,
strong {
    color: #DEDEDE;
    /* variable */
}

mark {
    background: #D3D40E;
}

blockquote {
    color: #9DA2A6;
}

table a {
    color: #DEDEDE;
    /* variable */
}

th,
td {
    border: solid 1px #474d54;
    /* variable */
}

.task-list {
    padding-left: 0;
}

.md-task-list-item {
    padding-left: 1.25rem;
}

.md-task-list-item > input {
    top: auto;
}

.md-task-list-item > input:before {
    content: "";
    display: inline-block;
    width: 0.875rem;
    height: 0.875rem;
    vertical-align: middle;
    text-align: center;
    border: 1px solid #b8bfc6;
    background-color: #363B40;
    margin-top: -0.4rem;
}

.md-task-list-item > input:checked:before,
.md-task-list-item > input[checked]:before {
    content: '\221A';
    /*◘*/
    font-size: 0.625rem;
    line-height: 0.625rem;
    color: #DEDEDE;
}

/** quick open **/
.auto-suggest-container {
    border: 0px;
    background-color: #525C65;
}

#typora-quick-open {
    background-color: #525C65;
}

#typora-quick-open input{
    background-color: #525C65;
    border: 0;
    border-bottom: 1px solid grey;
}

.typora-quick-open-item {
    background-color: inherit;
    color: inherit;
}

.typora-quick-open-item.active,
.typora-quick-open-item:hover {
    background-color: #4D8BDB;
    color: white;
}

.typora-quick-open-item:hover {
    background-color: rgba(77, 139, 219, 0.8);
}

.typora-search-spinner > div {
  background-color: #fff;
}

#write pre.md-meta-block {
    border-bottom: 1px dashed #ccc;
    background: transparent;
    padding-bottom: 0.6em;
    line-height: 1.6em;
}

.btn,
.btn .btn-default {
    background: transparent;
    color: #b8bfc6;
}

.ty-table-edit {
    border-top: 1px solid gray;
    background-color: #363B40;
}

.popover-title {
    background: transparent;
}

.md-image>.md-meta {
    color: #BBBBBB;
    background: transparent;
}

.md-expand.md-image>.md-meta {
    color: #DDD;
}

#write>h3:before,
#write>h4:before,
#write>h5:before,
#write>h6:before {
    border: none;
    border-radius: 0px;
    color: #888;
    text-decoration: underline;
    left: -1.4rem;
    top: 0.2rem;
}

#write>h3.md-focus:before {
    top: 2px;
}

#write>h4.md-focus:before {
    top: 2px;
}

.md-toc-item {
    color: #A8C2DC;
}

#write div.md-toc-tooltip {
    background-color: #363B40;
}

.dropdown-menu .btn:hover,
.dropdown-menu .btn:focus,
.md-toc .btn:hover,
.md-toc .btn:focus {
    color: white;
    background: black;
}

#toc-dropmenu {
    background: rgba(50, 54, 59, 0.93);
    border: 1px solid rgba(253, 253, 253, 0.15);
}

#toc-dropmenu .divider {
    background-color: #9b9b9b;
}

.outline-expander:before {
    top: 2px;
}

#typora-sidebar {
    box-shadow: none;
    border-right: 1px dashed;
    border-right: none;
}

.sidebar-tabs {
    border-bottom:0;
}

#typora-sidebar:hover .outline-title-wrapper {
    border-left: 1px dashed;
}

.outline-title-wrapper .btn {
    color: inherit;
}

.outline-item:hover {
    border-color: #363B40;
    background-color: #363B40;
    color: white;
}

h1.md-focus .md-attr,
h2.md-focus .md-attr,
h3.md-focus .md-attr,
h4.md-focus .md-attr,
h5.md-focus .md-attr,
h6.md-focus .md-attr,
.md-header-span .md-attr {
    color: #8C8E92;
    display: inline;
}

.md-comment {
    color: #5a95e3;
    opacity: 1;
}

.md-inline-math svg {
    color: #b8bfc6;
}

#math-inline-preview .md-arrow:after {
    background: black;
}

.modal-content {
    background: var(--bg-color);
    border: 0;
}

.modal-title {
    font-size: 1.5em;
}

.modal-content input {
    background-color: rgba(26, 21, 21, 0.51);
    color: white;
}

.modal-content .input-group-addon {
    color: white;
}

.modal-backdrop {
    background-color: rgba(174, 174, 174, 0.7);
}

.modal-content .btn-primary {
    border-color: var(--primary-color);
}

.md-table-resize-popover {
    background-color: #333;
}

.form-inline .input-group .input-group-addon {
    color: white;
}

#md-searchpanel {
    border-bottom: 1px dashed grey;
}

/** UI for electron */

.context-menu,
#spell-check-panel,
#footer-word-count-info {
    background-color: #42464A;
}

.context-menu.dropdown-menu .divider,
.dropdown-menu .divider {
    background-color: #777777;
}

footer {
    color: inherit;
}

@media (max-width: 1000px) {
    footer {
        border-top: none;
    }
    footer:hover {
        color: inherit;
    }
}

#file-info-file-path .file-info-field-value:hover {
    background-color: #555;
    color: #dedede;
}

.megamenu-content,
.megamenu-opened header {
    background: var(--bg-color);
}

.megamenu-menu-panel h2,
.megamenu-menu-panel h1,
.long-btn {
    color: inherit;
}

.megamenu-menu-panel input[type='text'] {
    background: inherit;
    border: 0;
    border-bottom: 1px solid;
}

#recent-file-panel-action-btn {
    background: inherit;
    border: 1px grey solid;
}

.megamenu-menu-panel .dropdown-menu > li > a {
    color: inherit;
    background-color: #2F353A;
    text-decoration: none;
}

.megamenu-menu-panel table td:nth-child(1) {
    color: inherit;
    font-weight: bold;
}

.megamenu-menu-panel tbody tr:hover td:nth-child(1) {
    color: white;
}

.modal-footer .btn-default, 
.modal-footer .btn-primary,
.modal-footer .btn-default:not(:hover) {
    border: 1px solid;
    border-color: transparent;
}

.btn-primary {
    color: white;
}

.btn-default:hover, .btn-default:focus, .btn-default.focus, .btn-default:active, .btn-default.active, .open > .dropdown-toggle.btn-default {
    color: white;
    border: 1px solid #ddd;
    background-color: inherit;
}

.modal-header {
    border-bottom: 0;
}

.modal-footer {
    border-top: 0;
}

#recent-file-panel tbody tr:nth-child(2n-1) {
    background-color: transparent !important;
}

.megamenu-menu-panel tbody tr:hover td:nth-child(2) {
    color: inherit;
}

.megamenu-menu-panel .btn {
    border: 1px solid #eee;
    background: transparent;
}

.mouse-hover .toolbar-icon.btn:hover,
#w-full.mouse-hover,
#w-pin.mouse-hover {
    background-color: inherit;
}

.typora-node::-webkit-scrollbar {
    width: 5px;
}

.typora-node::-webkit-scrollbar-thumb:vertical {
    background: rgba(250, 250, 250, 0.3);
}

.typora-node::-webkit-scrollbar-thumb:vertical:active {
    background: rgba(250, 250, 250, 0.5);
}

#w-unpin {
    background-color: #4182c4;
}

#top-titlebar, #top-titlebar * {
    color: var(--item-hover-text-color);
}

.typora-sourceview-on #toggle-sourceview-btn,
#footer-word-count:hover,
.ty-show-word-count #footer-word-count {
    background: #333333;
}

#toggle-sourceview-btn:hover {
    color: #eee;
    background: #333333;
}

/** focus mode */
.on-focus-mode .md-end-block:not(.md-focus):not(.md-focus-container) * {
    color: #686868 !important;
}

.on-focus-mode .md-end-block:not(.md-focus) img,
.on-focus-mode .md-task-list-item:not(.md-focus-container)>input {
    opacity: #686868 !important;
}

.on-focus-mode li[cid]:not(.md-focus-container){
    color: #686868;
}

.on-focus-mode .md-fences.md-focus .CodeMirror-code>*:not(.CodeMirror-activeline) *,
.on-focus-mode .CodeMirror.cm-s-inner:not(.CodeMirror-focused) * {
    color: #686868 !important;
}

.on-focus-mode .md-focus,
.on-focus-mode .md-focus-container {
    color: #fff;
}

.on-focus-mode #typora-source .CodeMirror-code>*:not(.CodeMirror-activeline) * {
    color: #686868 !important;
}


/*diagrams*/
#write .md-focus .md-diagram-panel {
    border: 1px solid #ddd;
    margin-left: -1px;
    width: calc(100% + 2px);
}

/*diagrams*/
#write .md-focus.md-fences-with-lineno .md-diagram-panel {
    margin-left: auto;
}

.md-diagram-panel-error {
    color: #f1908e;
}

.active-tab-files #info-panel-tab-file,
.active-tab-files #info-panel-tab-file:hover,
.active-tab-outline #info-panel-tab-outline,
.active-tab-outline #info-panel-tab-outline:hover {
    color: #eee;
}

.sidebar-footer-item:hover,
.footer-item:hover {
    background: inherit;
    color: white;
}

.ty-side-sort-btn.active,
.ty-side-sort-btn:hover,
.selected-folder-menu-item a:after {
    color: white;
}

#sidebar-files-menu {
    border:solid 1px;
    box-shadow: 4px 4px 20px rgba(0, 0, 0, 0.79);
    background-color: var(--bg-color);
}

.file-list-item {
    border-bottom:none;
}

.file-list-item-summary {
    opacity: 1;
}

.file-list-item.active:first-child {
    border-top: none;
}

.file-node-background {
    height: 32px;
}

.file-library-node.active>.file-node-content,
.file-list-item.active {
    color: white;
    color: var(--active-file-text-color);
}

.file-library-node.active>.file-node-background{
    background-color: rgb(34, 34, 34);
    background-color: var(--active-file-bg-color);
}
.file-list-item.active {
    background-color: rgb(34, 34, 34);
    background-color: var(--active-file-bg-color);
}

#ty-tooltip {
    background-color: black;
    color: #eee;
}

.md-task-list-item>input {
    margin-left: -1.3em;
    margin-top: 0.3rem;
    -webkit-appearance: none;
}

.md-mathjax-midline {
    background-color: #57616b;
    border-bottom: none;
}

footer.ty-footer {
    border-color: #656565;
}

.ty-preferences .btn-default {
    background: transparent;
}
.ty-preferences .btn-default:hover {
    background: #57616b;
}

.ty-preferences select {
    border: 1px solid #989698;
    height: 21px;
}

.ty-preferences .nav-group-item.active {
    background: var(--item-hover-bg-color);
}

.ty-preferences input[type="search"] {
    border-color: #333;
    background: #333;
    line-height: 22px;
    border-radius: 6px;
    color: white;
}

.ty-preferences input[type="search"]:focus {
    box-shadow: none;
}

[data-is-directory="true"] .file-node-content {
    margin-bottom: 0;
}

.file-node-title {
    line-height: 22px;
}

.html-for-mac .file-node-open-state, .html-for-mac .file-node-icon {
    line-height: 26px;
}

::-webkit-scrollbar-thumb {
    background: rgba(230, 230, 230, 0.30);
}

::-webkit-scrollbar-thumb:active {
    background: rgba(230, 230, 230, 0.50);
}

#typora-sidebar:hover div.sidebar-content-content::-webkit-scrollbar-thumb:horizontal {
    background: rgba(230, 230, 230, 0.30);
}

.nav-group-item:active {
    background-color: #474d54;
}

.md-search-hit {
    background: rgba(199, 140, 60, 0.81);
    color: #eee;
}

.md-search-hit * {
    color: #eee;
}

#md-searchpanel input {
    color: white;
}

.export-detail,
.export-item.active,
.export-items-list-control {
    background: #d6d6d4
}

.modal-backdrop.in {
    opacity: 1;
    backdrop-filter: blur(1px);
}

 :root {--mermaid-font-zoom:1.25em ;} 
</style>
</head>
<body class='typora-export os-windows'>
<div id='write'  class=''><h1><a name="segnet--a-deep-convolutional-encoder-decoder-architecture-for-image-segmentation" class="md-header-anchor"></a><span>SegNet : A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</span></h1><ul><li><span>paper : </span><a href='https://arxiv.org/pdf/1511.00561.pdf'><span>https://arxiv.org/pdf/1511.00561.pdf</span></a></li></ul><h2><a name="0-abstract" class="md-header-anchor"></a><span>0</span><span>.</span><span> Abstract</span></h2><ol start='' ><li><p><span>VGG16 에서 FC-Layer 3개를 제외한 13개의 Layer으로 구성된 Encoder를 사용</span></p></li><li><p><span>Encoder와 정반대의 Decoder를 이용해서 resolution을 증가시킴</span></p><ul><li><span>이때, UnMaxpool을 이용해서 non-linear한 Upsampling을 진행함</span></li><li><span>Unpooling의 경우 학습할 필요가 없어서 파라미터 및 속도의 장점이 있음</span></li><li><span>UnMaxpool 만 사용할 경우에 Upsampled maps이 Sparse한 단점이 있어서 Conv를 같이 사용해서 Dense하게 만듬</span></li></ul></li><li><p><span>FCN / DeepLab-LargeFOV, DeconvNet과 비교</span></p><ul><li><span>메모리 및 정확도, 속도의 관점</span></li></ul></li><li><p><span>특히, scene understanding의 분야에서 동기를 얻고 이에 대한 테스크를 수행하려고 함</span></p><ul><li><span>Scene understanding application 분야는 속도와 메모리가 중요</span></li></ul></li><li><p><span>다른 모델에 비해 파라미터가 적어서 속도, 메모리 측면에서 효율적임</span></p></li></ol><h2><a name="1-introduction" class="md-header-anchor"></a><span>1</span><span>.</span><span> Introduction</span></h2><p><span>두 가지의 동기를 통해서 SegNet이라는 모델의 아키텍처를 고안했음</span></p><ol start='' ><li><span>Max Pooling 및 Sub Sampling을 통해서 줄어든 특징 맵의 해상도를 증가시킬지에 대한 고민</span></li><li><span>Road Scene Understanding applications라는 분야에서 Semantic Segmentation을 수행하기 위해서 모델이 필요한 능력에 대한 고민</span></li></ol><p><span>특히, Road Scene Undestanding 분야의 경우 몇가지 특징이 존재함</span></p><ol start='' ><li><span>Scene understanding에서 objects간의 관계를 이해 하는데에 Semantic segmentation 사용</span></li><li><span>Scene understanding의 경우 appearance(road, building)과 shape(cars, pedestrians)를 이해하고 그들간의 관계를 이해할 필요가 있음 (road – cars, pedestrians – side-walk)</span><br/><img src="https://drive.google.com/uc?export=view&amp;id=16o4YLm843HOunMFVPdMyzLQL_Tpg_ESh" referrerpolicy="no-referrer" alt="image-20210125005100661"></li></ol><h2><a name="3-architecture" class="md-header-anchor"></a><span>3</span><span>.</span><span> Architecture</span></h2><p><img src="https://drive.google.com/uc?export=view&amp;id=1sYQHFDQijeNFo9CCcHmAe4EDq1uzIphK" referrerpolicy="no-referrer" alt="image-20210125005146494"></p><ol start='' ><li><p><span>VGG16의 13개 층을 Encoder로 사용하고 뒤집은 부분을 Decoder로 사용</span></p><ul><li><span>중간의 Fully Connected Layer 부분을 제거해서 학습 파라미터를 줄임 (134M -&gt; 14.7M)</span></li></ul></li><li><p><span>Enocoder 부분은 pretrained 된 네트워크를 사용</span></p><ul><li><span>Conv + BN + ReLU</span></li></ul></li><li><p><span>MaxPooling의 장점과 단점</span></p><ul><li><span>Max Pooling – 2x2 window with stride 2 (overlapped 안되도록)</span></li><li><span>Max Pooling을 통해 translation invariance + large context를 each pixel에 담음</span></li><li><span>spatial resolution이 사라지는 문제가 발생 (디테일한 부분이 사라짐)</span></li><li><span>위의 문제점을 잡아 주기위한 장치가 필요하고 이게 UnMaxPooling 기법</span></li></ul></li><li><p><span>UnMaxPooling의 장점과 단점</span></p><ul><li><span>메모리의 효율성 + 학습 및 인퍼런스 속도가 빠름</span></li><li><span>경계에 대한 정보를 효율적으로 저장할 수 있음</span></li></ul></li><li><p><span>다른 Architectures과의 비교 (DeconvNet / UNet)</span></p><ul><li><span>DeconvNet : FC Layer + 2 stage training + larger parameterization</span></li><li><span>UNet : Use Feature map / don’t use pretrained weight of VGG net</span></li></ul></li></ol><h3><a name="31-decoder-variants" class="md-header-anchor"></a><span>3.1 Decoder Variants</span></h3><p><img src="https://drive.google.com/uc?export=view&amp;id=1U3KiGGJxXo7lzZkXIVzJsaTKdxPZyPOO" referrerpolicy="no-referrer" alt="image-20210125005447762"></p><ol start='' ><li><span>SegNet의 small version으로 4 encoders와 4 decoders으로 구성 (SegNet은 5개씩으로 구성)</span></li><li><span>Encoders는 max-pooling 과 sub-sampling을 수행하고 이때의 indice를 받아서 unmaxsampling을 수행</span></li><li><span>Conv layer 이후에는 BN 이 사용되고 Bias는 없음</span></li><li><span>Decoder Network에는 Relu, Bias 를 사용하지 않음</span></li><li><span>7x7 의 conv을 이용해서 wide context를 잡으려고함</span></li></ol><p><img src="https://drive.google.com/uc?export=view&amp;id=1plUchw1aMn8i8foV8EiSETCsiSFwJEBB" referrerpolicy="no-referrer" alt="image-20210125005812669"></p><ol start='' ><li><span>SegNet-Basic과 Encoder는 동일하게 사용</span></li><li><span>Decoder에는 UnMaxPooling이 아닌 Transposed Convolution으로 전부 대체</span></li></ol><h3><a name="32-training" class="md-header-anchor"></a><span>3.2 Training</span></h3><p><img src="https://drive.google.com/uc?export=view&amp;id=1KBO2iQhkWlqVAFQuAIJsolhznBO7iCxW" referrerpolicy="no-referrer" alt="image-20210125010114862"></p><ol start='' ><li><p><span>Camvid Dataset</span></p><ul><li><span>Training Dataset : 367</span></li><li><span>Test Dataset : 233</span></li><li><span>Class : 12 (배경포함 )</span></li></ul></li><li><p><span>Initialized (He initialized)</span></p></li><li><p><span>Optimization : SGD (lr : 0.1, momentum 0.9)</span></p></li><li><p><span>validation score가 가장 높은 Epoch 선택</span></p></li><li><p><span>Cross Entropy Loss</span></p></li><li><p><span>Medium Frequency Balancing</span></p><ul><li><span>larger Class의 weight를 1보다 작게 설정</span></li></ul></li></ol><h3><a name="33-analysis" class="md-header-anchor"></a><span>3.3 Analysis</span></h3><ol start='0' ><li><p><span>실험을 위한 평가함수와 테스트 데이터셋 세팅</span></p><ul><li><p><span>Performance Metric</span></p><ul><li><p><span>Global Accuracy (Pixel Accuracy - G)</span></p></li><li><p><span>Class average accuracy (Mean Pixel Accuracy - C)</span></p></li><li><p><span>mean Intersection over union (mIoU)</span></p></li><li><p><span>Boundary F1-measure (BF)</span></p><ul><li><span>mIoU의 경우 계산방법과 사람이 인식하는 경계부분이 좀 다른데, 이를 보완하기 위해 경계부분에 대해서 정확도를 측정하는 방법</span></li></ul></li></ul></li><li><p><span>Test Set (CAMVID)</span></p><ul><li><span>CamVid validation set을 기준으로 global accuracy가 가장 높은 Epoch로 추론</span></li><li><span>하지만, 도로와 건물, 하늘, 보도처럼 대부분의 이미지를 차지하는 클래스 때매 클래스의 평균 정확도가 높다고해서 Global Accuracy가 높은게 아님</span></li></ul></li></ul></li></ol><p><img src="https://drive.google.com/uc?export=view&amp;id=1wrOoau6ppofAe589YNBdC5nv6Efl5vt_" referrerpolicy="no-referrer" alt="image-20210125011316214"></p><ol start='' ><li><p><span>3가지 경우에 대해서 각각 성능을 비교 (파라미터 / 추론속도 / 성능)</span></p><ul><li><span>unsampling의 종류 (Bilinear / Upsampling – indices / Learning to upsample)</span></li><li><span>Median frequency balancing</span></li><li><span>Natural frequency balancing</span></li></ul></li><li><p><span>Bilinear-Interpolation without any learning performs의 경우</span></p></li></ol><p><img src="https://drive.google.com/uc?export=view&amp;id=1YfJ7ZqxF8HWWZSMfsx382YGJoE-_dgva" referrerpolicy="no-referrer" alt="image-20210125011429289"></p><ol start='3' ><li><span>SegNet-Basic vs FCN-Basic</span></li></ol><p><img src="https://drive.google.com/uc?export=view&amp;id=16kOGG_XbHRMarL250SahqFFeCTGNohu8" referrerpolicy="no-referrer" alt="image-20210125011450220"></p><ul><li><p><span>SegNet-Basic : Less memory (Storage multiplier)</span></p></li><li><p><span>FCN-Basic : encoder feature maps</span></p><ul><li><span>encoder 층마다 feature maps 필요</span></li><li><span>Faster Inference time (Deconvolution layer가 적음)</span></li></ul></li></ul><ol start='4' ><li><span>Others</span></li></ol><p><img src="https://drive.google.com/uc?export=view&amp;id=1zqNVWXRclKZhrDxHgiPjLMQ1fW7pykfF" referrerpolicy="no-referrer" alt="image-20210125011842347"></p><ul><li><p><span>SegNet-Basic-SingleChannelDecoder : 추론속도와 파라미터의 수가 엄청 작음</span></p></li><li><p><span>SegNet-Basic-EncoderAddition : Unsampling시에 Max-pooling Indices를 사용</span></p></li><li><p><span>FCN-Basic-NoDimReduction : 성능이 가장 높고 Infer time도 작음. 파라미터와 메모리의 경우 1.625M과 64로 가장 큼</span></p></li><li><p><span>FCN-Basic-NoAddition-NoDimReduction : Addition을 제거시에 정확도가 많이 감소 84.8 -&gt; 67.8</span></p></li><li><p><span>SegNet-Basic-EncoderAddition, FCN-Basic-NoDimReduction과 같이 무거운 모델이 성능이 높음</span></p><ul><li><span>FCN에서는 차원축소를 제거하는게 성능과 BF 측면에서 성능향상이 큼</span></li><li><span>Memory와 정확도 사이에는 Trade-off 관계를 보임</span></li></ul></li></ul><ol start='5' ><li><p><span>Summary</span></p><ul><li><span>인코더 기능 맵이 완전히 저장되어 있을 때 최상의 성능을 얻을 수 있음. 특히 의미론적 등고선 설명 메트릭(BF)에 확하게 반영됨</span></li><li><span>추론 중 메모리가 제한될 때, 압축된 형태의 인코더 특징 맵(차원 감소, 최대 풀링 지수)을 적절한 디코더(예: SegNet 유형)와 함께 저장 및 사용하여 성능을 개선할 수 있음</span></li><li><span>Decoder의 깊이가 커지면 성능이 향상함</span></li></ul></li></ol><h2><a name="4-benchmarking" class="md-header-anchor"></a><span>4</span><span>.</span><span> Benchmarking</span></h2><h3><a name="41-road-scene-segmentation" class="md-header-anchor"></a><span>4.1 Road Scene Segmentation</span></h3><p><img src="https://drive.google.com/uc?export=view&amp;id=10Hvyfhh1nEhMC44uX4Mfnv3jCaq4Tykb" referrerpolicy="no-referrer" alt="image-20210125012527739"></p><p><img src="https://drive.google.com/uc?export=view&amp;id=1GMBfFVur9dKBI3lv67Un3licuasxHEvb" referrerpolicy="no-referrer" alt="image-20210125012546836"></p><ul><li><p><span>FCN과 DeconvNet에 비해서 SegNet과 DeepLabv1은 적은 iteration에서 높은 성능을 보임</span></p><ul><li><span>40K, 80K 에서 성능의 차이가 특히 발생하고 &gt;80K에서는 DeconvNet하고 성능은 비슷한 모습을 보이고, 오히려 BF 부분은 DeconvNet의 성능이 더 높음</span></li><li><span>SegNet과 DeepLabv1은 G, C, mIoU에 대해서는 초기에는 성능이 거의 비슷하고 Iteration이 늘어날 수록 차이가 발생 (BF의 경우 40K에서도 SegNet이 우수)</span></li></ul></li></ul><p><img src="https://drive.google.com/uc?export=view&amp;id=17PFTCCeNfIGX9sicy0p4xlYDf_Wxk-3z" referrerpolicy="no-referrer" alt="image-20210125012532699"></p><h3><a name="42-sun-rgb-d-indoor-scenes" class="md-header-anchor"></a><span>4.2 SUN RGB-D Indoor Scenes</span></h3><p><img src="https://drive.google.com/uc?export=view&amp;id=1vR1WP3DWmTOsFP0HrlSmxjcJUij6P7oC" referrerpolicy="no-referrer" alt="image-20210125012649178"></p><ul><li><p><span>Deep Architectures (SegNet, DeconvNet)가 80K에서 낮은 성능을 보임 (G, C, mIoU)</span></p></li><li><p><span>SegNet의 경우 G와 BF가 DeepLab-LargeFOV 보다 높은 경향을 보이지만 C와 mIoU는 높은 경향을 보이고 CamVid 데이터셋에 비해 성능이 많이 감소함</span></p><ul><li><span>첫번째 원인은 Class의 수가 증가했고, small class가 이미지에 많이 등장하는 경향이 있음</span></li><li><span>두번째 원인은 VGG를 사용하는 Deep한 Architecture때문에 발생 (파라미터가 많아서 수렴 x, 정보손실이 큼)</span></li></ul><p><img src="https://drive.google.com/uc?export=view&amp;id=1EPpz3_0ITxssksasDhJy3nov5euQjx4u" referrerpolicy="no-referrer" alt="image-20210125012717342"></p></li></ul><h2><a name="5-discussion-and-future-work" class="md-header-anchor"></a><span>5</span><span>.</span><span> Discussion and Future Work</span></h2><ol start='' ><li><p><span>보통의 Deep Learning은 모델이 깊고, 데이터가 많고, 학습이 길어지면 성능이 좋아짐</span></p><ul><li><span>실험 결과처럼 학습 시간의 상승이 성능의 향상이 크게 관련 없을경우 학습 시간이 중요함(?)</span></li><li><span>인퍼런스 시간과 메모리 역시 AR, 자율주행과 같은 특수한 분야에서 매우 중요</span></li><li><span>전반적인 효율성(성능, 메모리, 학습 및 테스트 시간)에서 SegNet은 효율적임</span></li></ul></li><li><p><span>Pascal, MS-COCO 처럼 Class가 적은 경우보다 Scene segmentation은 Class가 훨씬 많고 동시에 등장해서 더 어려움</span></p></li><li><p><span>속도 및 메모리, 성능에 대해서 동일한 비교를 하기 위해서 End-to-End의 학습 및 추론을 사용 (DeconvNet의 경우 Instance-wise Segmentation을 하는데 그렇지 않았다는 의미같음)</span></p></li></ol><h2><a name="6-conclusion" class="md-header-anchor"></a><span>6</span><span>.</span><span> Conclusion</span></h2><ol start='' ><li><p><span>road and indoor scene understanding 분야에서 동기를 얻어서 memory와 computational time을 효율적으로 만드려고 시도</span></p></li><li><p><span>SegNet을 다른 논문인 FCN, DeconvNet 등과 비교해서 architectures에 따라서 어떤 식으로 정확도, 학습 및 추론 속도 등이 trade-offs 관계를 가지는지 파악</span></p></li><li><p><span>Encoder network feature maps를 저장해서 활용하는게 성능은 가장 좋지만 inference time과 memory 측면에서 좋지 않음</span></p></li><li><p><span>위의 3의 성능을 보완하기위해서 max-pooling indices를 사용하면 충분히 좋은 성능에 도달</span></p></li><li><p><span>추후, End-to-End의 학습이 잘 되도록 개선할 예정</span></p></li><li><p><span>SegNet은 FCN, DeepLab v1 보다는 느리지만 DeconvNet 보다는 빠름</span></p><p><img src="https://drive.google.com/uc?export=view&amp;id=1D-8aYzvjxIQjUa8KcnjlNHWdatiw2D8A" referrerpolicy="no-referrer" alt="image-20210125012924245"></p><ul><li><span>FCN, DeepLabv1에 비해 SegNet은 Decoder Architecture가 있어서 느릴 수밖에 없음</span></li><li><span>DeconvNet에서 FC Layer를 제거한 구조여서 DeconvNet 보다는 속도가 빠름</span></li></ul></li><li><p><span>SegNet은 Traning, Inference memory가 작은 편이고 Model Size 또한 FCN, DeconvNet에 비해 작음</span></p></li><li><p><span>Object의 크기가 큰 경우에 대해서는 잘 맞추는 모습을 보이지만, 반대의 경우에 대해서는 성능이 떨어지는 모습을 보임</span></p><p><img src="https://drive.google.com/uc?export=view&amp;id=192p_jZzTsu_q__Y_nUtEWxSxwuM4_0dw" referrerpolicy="no-referrer" alt="image-20210125012944893"></p></li></ol><h3><a name="61-advantages" class="md-header-anchor"></a><span>6.1 Advantages</span></h3><ol start='' ><li><p><span>Scene Understanding이라는 특수한 분야의 Task에 초점을 맞춰서 문제를 해결하려고함</span></p><ul><li><span>Object의 크기가 크다는 점</span></li><li><span>Object간에 동시에 발생하고 서로 관계가 있다는 점 (보행자-인도, 자동차-도로)</span></li><li><span>자율주행의 경우 Inference 속도가 빨라야 한다는 점</span></li></ul></li><li><p><span>구조 자체가 DeconvNet에서 Fully Connected Layer만 뺀 구조라서 SegNet의 장점을 어필하기 위해 다양한 시도와 초점을 맞춰서 진행</span></p><ul><li><span>Scene 분야 / Memory 및 Training, Inference Time / Parameter에 의한 오버피팅</span></li><li><span>DeconvNet vs SegNet / FCN vs SegNet / Unet vs Segnet</span></li><li><span>Iterations이 적은 경우와 많은 경우에 대해 성능이 어떻게 나오는지 비교</span></li><li><span>클래스의 크기가 작은 경우와 많은 경우에 대해 성능이 어떻게 나오는지 비교</span></li></ul></li></ol><h3><a name="62-disadvantages" class="md-header-anchor"></a><span>6.2 Disadvantages</span></h3><ol start='' ><li><p><span>DeconvNet에 Fully Connected Layer만 뺀 논문치고는 굉장히 화려한게 아닌가 생각이 듬 (시점으로보면 미리 준비하고 있었는데 DeconvNet이 나와서 arxiv에 낸게 아닌가 불쌍하기도함)</span></p></li><li><p><span>CamVid와 SUNRGB-D 라는 특수한 데이터셋에 대해서는 성능이 제일 좋았지만 다른 데이터셋에 대해서는 어떻게 나왔을지 비교가 필요(일반화성능)</span></p><ul><li><span>참고로 FCN, DeconvNet, DeepLab 논문의 경우 위의 2개 데이터에 대해서 실험을 한 내용이 없어서 직접 구현해서 돌렸을텐데 튜닝을 어느정도 했을지에 대한 의문도 남음</span></li><li><span>PASCAL VOC 2012에 대해서도 비교를 해야 정확한 결과였을 것 같음</span></li><li><span>Global Accuracy가 가장 높은거로 선택했다고 했는데 mIoU나 다른 지표로 weight를 선택해서 실험했을때 어떤 결과가 나왔을지에 대해 궁금</span></li></ul></li><li><p><span>Large Object를 잡고 Object간의 관계를 파악하는 것을 수행하는게 MaxPooling -&gt; UnMaxPooling인데 과연 이걸로 충분한가? 사실 DeconvNet도 위의 장치가 있는게 결과 차이가 너무 나는게 이상함. Fully Connected Layer 있고 없고에 대해서 어떤 차이가 나오는지 등에 대해 정확한 분석이 들어가야 되고 위의 원인이 맞는지도 의심스러움</span></p></li><li><p><span>같은 얘기 너무 반복함. 모든 내용에 Training Time / Computation / Memory 중요하다는 얘기가 반복되고 FCN이나 다른 방법에 비해 크게 상승했는지도 의문임</span></p></li><li><p><span>CamVid Data가 가지고 있는 문제점</span></p><ul><li><p><span>SegNet의 실험 대부분이 CamVid에서 비교했는데 해당 데이터는 약간의 문제가 있음</span></p><ul><li><span>Input / Output data가 Time Correlated됨</span></li></ul><p><img src="https://drive.google.com/uc?export=view&amp;id=13cObpRnnos4YyEDJAuSQBhNwIkI6691k" referrerpolicy="no-referrer" alt="image-20210125014232260"></p><ul><li><p><span>Dataset의 수가 작고 이상한 라벨들이 존재</span></p><ul><li><span>Train 367 / Test 233</span></li><li><span>Weird Label이 존재 (Bycycle == Person / 라벨이 자세하지 않음)</span></li></ul></li></ul></li></ul></li></ol><p><img src="https://drive.google.com/uc?export=view&amp;id=1cDWtjfDZkaFQgwBTXdg5-DzQdklJCv9D" referrerpolicy="no-referrer" alt="image-20210125013424071"></p><h2><a name="7-appendix" class="md-header-anchor"></a><span>7</span><span>.</span><span> Appendix</span></h2><h3><a name="71-참고자료" class="md-header-anchor"></a><span>7.1 참고자료</span></h3><ol start='' ><li><span>J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015</span></li><li><span>A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012</span></li><li><span>K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014</span></li><li><span>C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014</span></li><li><span>B. Hariharan, P. Arbelaez, L. Bourdev, S. Maji, and J. Malik. ´ Semantic contours from inverse detectors. In ICCV, 2011</span></li><li><span>C. L. Zitnick and P. Dollar. Edge boxes: Locating object ´ proposals from edges. In ECCV, 2014</span></li><li><a href='https://medium.com/@sunnerli/simple-introduction-about-hourglass-like-model-11ee7c30138'><span>https://medium.com/@sunnerli/simple-introduction-about-hourglass-like-model-11ee7c30138</span></a></li></ol><h3><a name="72-기존의-네트워크와의-비교" class="md-header-anchor"></a><span>7.2 기존의 네트워크와의 비교</span></h3><p><img src="https://drive.google.com/uc?export=view&amp;id=1Rjm8f0XOYS05KcRIioAp0kTMRzulITi3" referrerpolicy="no-referrer" alt="image-20210125013713262"></p><p><span>이미지 출처 : </span><a href='https://medium.com/@sunnerli/simple-introduction-about-hourglass-like-model-11ee7c30138'><span>https://medium.com/@sunnerli/simple-introduction-about-hourglass-like-model-11ee7c30138</span></a></p></div>
</body>
</html>